# Predicting Spotify Artist Popularity from Network Centrality

This repository contains a PySpark / NetworkX project that predicts **Spotify artist popularity** using **linear regression** on graph-based **centrality measures** computed from an artist collaboration network.

The core idea:  
Artists are nodes in a collaboration graph; edges connect artists who have collaborated. We compute several **node centrality metrics** and use them, along with follower counts, to predict each artistâ€™s Spotify popularity score.

---

## ğŸ§ Project Overview

**Data source**

- Dataset: *Spotify Artist Feature & Collaboration Network* (Kaggle)  
- Downloaded programmatically using `kagglehub`  
- Key files from the dataset:
  - `edges.csv` â€” collaboration edges (artist \`spotify_id\` pairs)
  - `nodes.csv` â€” artist metadata (ID, name, followers, popularity, etc.)

**Main steps in the pipeline**

1. **Build the collaboration graph**
   - Use `NetworkX` to create an undirected graph from `edges.csv`.
   - Ensure all artists in `nodes.csv` exist as nodes in the graph.

2. **Compute centrality measures** (on a sampled subgraph for efficiency)
   - Degree centrality  
   - Betweenness centrality  
   - Closeness centrality  
   - Eigenvector centrality  
   - PageRank  
   - Map \`spotify_id\` â†’ artist name for readability.

3. **Inspect most central artists**
   - Print the top 5 artists by each centrality metric to see who dominates the network structure.

4. **Prepare a modeling dataset (Pandas â†’ CSV â†’ Spark)**
   - Build a Pandas dataframe with:
     - \`spotify_id\`, \`Artist\`
     - \`Degree\`, \`Betweenness\`, \`Closeness\`, \`Eigenvector\`, \`PageRank\`
   - Save as \`pd_centrality_scores.csv\`.
   - Load it into Spark as \`df1\`.
   - Load artist metadata (including \`followers\`, \`popularity\`) as \`df2\` from \`spotify_nodes.csv\`.
   - Inner-join on \`spotify_id\` and drop problematic rows / NAs.
   - Log-transform followers with \`log_followers = log1p(followers)\`.

5. **Feature engineering & scaling (PySpark)**
   - Features used in the linear regression:
     - \`Degree\`
     - \`Betweenness\`
     - \`Closeness\`
     - \`Eigenvector\`
     - \`log_followers\`
   - Assemble these into a single feature vector using \`VectorAssembler\`.
   - Standardize features via \`StandardScaler\` to get \`features_scaled\`.

6. **Linear regression model**
   - Split into train/test: 80% / 20%.
   - Train a \`LinearRegression\` model with:
     - \`featuresCol="features_scaled"\`
     - \`labelCol="popularity"\`
     - \`predictionCol="pred_popularity"\`
   - Extract coefficients and intercept into a small Pandas table for inspection.
   - Generate predictions with \`pred_popularity\` for each artist in the test set.

7. **Model evaluation**
   - Report:
     - Root Mean Squared Error (**RMSE**)
     - Mean Absolute Error (**MAE**)
     - Coefficient of determination (**RÂ²**)

---

## ğŸ“ Repository Structure

A minimal structure for this project:

```text
.
â”œâ”€ spotify_linear_regression.py   # Main script (exported from Colab)
â”œâ”€ pd_centrality_scores.csv       # Saved centrality measures (generated by the script)
â”œâ”€ spotify_nodes.csv              # Artist metadata (followers, popularity, etc.)
â”œâ”€ requirements.txt               # Python dependencies
â”œâ”€ README.md                      # This file
â””â”€ .gitignore                     # Ignore cache / env / Spark junk
```

> Note:  
> \`spotify_nodes.csv\` is expected to contain at least: \`spotify_id\`, \`name\`, \`followers\`, \`popularity\`.  
> In Colab, you can create it by exporting or renaming the original \`nodes.csv\` from the Kaggle dataset.

---

## âš™ï¸ Installation & Setup

### 1. Clone the repository

```bash
git clone https://github.com/<your-username>/spotify-artist-centrality-regression.git
cd spotify-artist-centrality-regression
```

### 2. (Optional) Create a virtual environment

```bash
python -m venv venv
source venv/bin/activate       # macOS / Linux
# OR
venv\Scriptsctivate          # Windows
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Configure Kaggle access (for `kagglehub`)

To allow `kagglehub` to download the dataset:

1. Create a Kaggle account and API token (\`kaggle.json\`).
2. Place \`kaggle.json\` under \`~/.kaggle/\` or follow \`kagglehub\`â€™s documentation for authentication.
3. The script will then download the dataset automatically when run.

Alternatively, you can manually download the dataset from Kaggle and adjust the \`path_csv\` in the script.

---

## â–¶ï¸ How to Run the Script

From the project root, run:

```bash
python spotify_linear_regression.py
```

What this will do:

1. Download and load the Kaggle collaboration dataset (if not already cached).
2. Build the NetworkX graph and compute centrality metrics for a sampled subgraph.
3. Save \`pd_centrality_scores.csv\`.
4. Load centrality + artist metadata into Spark.
5. Assemble and scale features.
6. Fit a linear regression model to predict \`popularity\`.
7. Print:
   - The top artists by each centrality metric.
   - Model coefficients.
   - RMSE, MAE, and RÂ² on the training data (and show prediction samples).

---

## ğŸ“Š Model & Features

**Target variable**

- \`popularity\` â€” Spotifyâ€™s artist popularity score from the metadata.

**Features (final model)**

- \`Degree\` â€” Local connectivity / number of collaborations in the sampled graph.
- \`Betweenness\` â€” How often an artist lies on shortest paths between others.
- \`Closeness\` â€” Inverse average distance to all reachable nodes.
- \`Eigenvector\` â€” Influence of an artist by being connected to other influential artists.
- \`log_followers\` â€” Log-transformed follower count (stabilizes skew).

**Additional metric**

- \`PageRank\` is computed and available in the centrality CSV but not included in the current linear model. Itâ€™s a natural candidate for future experiments.

---

## ğŸ”® Possible Extensions

Ideas for future work:

- Add \`PageRank\` to the regression features and compare performance.
- Try **Lasso** or **Ridge** regression to study feature importance and regularization.
- Include genre, country, or other artist metadata as extra predictors.
- Use a **test set** evaluation using \`RegressionMetrics\` explicitly.
- Switch from a single linear model to:
  - Gradient-boosted trees
  - Random forests
  - Neural networks
- Visualize:
  - Centrality distributions
  - Network subgraphs of highly central artists

---

## ğŸ“¦ Requirements

The core Python stack used:

```text
networkx
pyspark
kagglehub
pandas
numpy
matplotlib
seaborn
```

All of these are listed in `requirements.txt`.

---

## ğŸ“ License

You can add a license (e.g., MIT) if you want to make the project explicitly reusable:

- MIT License: https://opensource.org/licenses/MIT

---

## ğŸ™Œ Acknowledgments

- Kaggle dataset: *Spotify Artist Feature & Collaboration Network*  
- Network analysis: `NetworkX`  
- Big data & modeling: `PySpark` MLlib
